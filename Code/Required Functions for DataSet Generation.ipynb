{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Required Functions for DataSet Generation.ipynb","provenance":[{"file_id":"1c9ZlbewNQ1jN6LKE3dFETYMOJyzw0x4N","timestamp":1591891531505},{"file_id":"1x_0nKQLHyl9ywqE1Ff6UZgjKicVJ7qn1","timestamp":1591879687993},{"file_id":"1c7XxSPwIzNCW7F7fhHqTp5_dg00yHIJS","timestamp":1591805570273}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YUrz_F8juSmW","colab_type":"code","colab":{}},"source":["# import necessary libraries\n","\n","import re\n","import os\n","import json\n","import nltk\n","import pandas as pd\n","from collections import OrderedDict \n","from nltk import sent_tokenize \n","from IPython.display import clear_output\n","import pandas as pd\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","import numpy as np\n","import pickle\n","\n","nltk.download('all')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"meKy1J6tietT","colab_type":"code","colab":{}},"source":["# Regex format matching dictionary\n","dict_regex = {}\n","#start and end\n","dict_regex['hh:mm:ss.ss ra'] = re.compile('\\d{1,2}:\\d{2}:\\d{2}\\.?\\d*')\n","dict_regex['dd:mm:ss.ss dec'] = re.compile('[+-]?\\d{1,2}:\\d{2}:\\d{2}\\.?\\d*')\n","\n","dict_regex['hh mm ss.ss ra'] = re.compile('\\d{1,2}\\s\\d{2}\\s\\d{2}\\.?\\d*')\n","dict_regex['dd mm ss.ss dec'] = re.compile('[+-]?\\d{1,2}\\s\\d{2}\\s\\d{2}\\.?\\d*')\n","\n","dict_regex['00h 00m 00.0s ra'] = re.compile('\\d{1,2}h\\s?\\d{2}m\\s?\\d{2}\\.?\\d*s?')\n","dict_regex['00d 00m 00.0s dec'] = re.compile('[+-]?\\d{1,2}d\\s?\\d{2}m\\s?\\d{2}\\.?\\d*s?')\n","\n","dict_regex['dd:mm:ss.ss ra'] = re.compile('\\d{1,3}:\\d{2}:\\d{2}\\.?\\d*')\n","dict_regex['dd mm ss.ss ra'] = re.compile('\\d{1,3}\\s\\d{2}\\s\\d{2}\\.?\\d*')\n","dict_regex['00d 00m 00.0s ra'] = re.compile('\\d{1,3}d\\s?\\d{2}m\\s?\\d{2}\\.?\\d*s?')\n","\n","dict_regex['00do 00\\' 00.0\\\" dec'] = re.compile('[+-]?\\d{1,2}[do]\\s?\\d{2}\\'\\s?\\d{2}\\.?\\d*(\\\"|\\'\\'|â€)')\n","\n","list_coords_regex = []\n","\n","list_coords_regex.append((dict_regex['hh:mm:ss.ss ra'], dict_regex['dd:mm:ss.ss dec']))\n","list_coords_regex.append((dict_regex['hh mm ss.ss ra'], dict_regex['dd mm ss.ss dec']))\n","list_coords_regex.append((dict_regex['00h 00m 00.0s ra'], dict_regex['00d 00m 00.0s dec']))\n","list_coords_regex.append((dict_regex['dd:mm:ss.ss ra'], dict_regex['dd:mm:ss.ss dec']))\n","list_coords_regex.append((dict_regex['dd mm ss.ss ra'], dict_regex['dd mm ss.ss dec']))\n","list_coords_regex.append((dict_regex['00d 00m 00.0s ra'], dict_regex['00d 00m 00.0s dec']))\n","list_coords_regex.append((dict_regex['00h 00m 00.0s ra'], dict_regex['00do 00\\' 00.0\\\" dec']))\n","list_coords_regex.append((dict_regex['00d 00m 00.0s ra'], dict_regex['00do 00\\' 00.0\\\" dec']))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPS6fgPX_tDy","colab_type":"code","colab":{}},"source":["def get_coordinates_except_decimal_sentences(sentence, start_index, lst_coords):\n","\n","    for coord_regex in list_coords_regex:\n","    \n","        ra_search_obj = coord_regex[0].search(sentence[start_index:])\n","    \n","        if ra_search_obj:\n","            ra_end_ind = ra_search_obj.end()\n","            dec_search_obj = coord_regex[1].search(sentence[start_index+ra_end_ind:])\n","            if dec_search_obj:\n","                lst_coords.append((ra_search_obj.group(), dec_search_obj.group()) )\n","                start_index_next = start_index + ( ra_end_ind + dec_search_obj.end() )\n","                get_coordinates_except_decimal_sentences(sentence, start_index_next, lst_coords)\n","            break\n","        else:\n","            continue\n","      \n","\n","def get_coordinates_except_decimal(content):\n","  lst = []\n","  for sentence in sent_tokenize(content):\n","    get_coordinates_except_decimal_sentences(sentence, 0, lst)\n","  return lst"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DllrRJcA-X5","colab_type":"code","colab":{}},"source":["# Sentence Tokenizer\n","\n","def my_tokenizer(input_string):         # UPDATED\n","    sentences = sent_tokenize(input_string)\n","    flag_idices = []\n","    sentences_new = []\n","    for sent_idx in range(0,len(sentences)):\n","        if( sent_idx in flag_idices ):\n","            continue\n","        temp_str = sentences[sent_idx]\n","        temp_idx = sent_idx\n","        tuple_end = (\"Decl.\", \"et al.\", 'e.g.', 'Coll.')\n","        while( sentences[temp_idx].endswith(tuple_end) ):\n","            flag_idices.append(temp_idx+1)\n","            if(temp_idx+1 >= len(sentences)):\n","                break\n","            temp_str += sentences[temp_idx+1]\n","            temp_idx+=1\n","        \n","        sentences_new.append(temp_str)\n","\n","    return sentences_new\n","\n","\n","def print_sentence(input_string):\n","        t_len = 0\n","        for j in range(len(input_string)):\n","            print(input_string[j], end='')\n","            t_len+=1\n","            if(t_len%100==0):\n","                print('\\n')\n","        print(\"\\n\")\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qA7g8IKSQNrH","colab_type":"code","colab":{}},"source":["# Some Preprocessing\n","\n","def process_sent(sentence):\n","    #stemmer object\n","    ps = PorterStemmer()\n","    #preserving the J2000 keyword \n","    review = re.sub('J2000', 'jtwothousand', sentence)\n","    #replacing all charactars except alphabets by space\n","    review = re.sub('[^a-zA-Z\\.]', ' ', review)\n","    #removing the single ' . '\n","    review = re.sub('\\s\\.\\s', ' ', review)\n","    #lowering all charactars \n","    review = review.lower()\n","    #splitting along the spaces\n","    review = review.split()\n","    #removing '.' from words\n","    review = [re.sub('\\.', '', word) for word in review]\n","    #stemming and removing stop words\n","    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n","    #joining the words to a sentence\n","    review = ' '.join(review)\n","    review = re.sub('decl', 'dec', review)\n","    if len(review)==0:\n","        return review\n","    #removing trailing '.'\n","    elif review[-1] == '.':\n","        review = review[:-1]\n","    return review\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5LnW65-GaL4V","colab_type":"code","colab":{}},"source":["#extract object name format\n","\n","def get_object_name_format(sentence):\n","    #filtering by removing sentences with the keyword grism\n","    if re.search('grism', sentence.lower()):\n","        return []\n","    lst_match = re.findall(r'\\d+\\.?\\d*[\\+-]\\d+\\.?\\d*', sentence) \n","    lst_output = []\n","    #adding matches only for cases length of ra is [4,6]\n","    #and length of dec is [3,6]\n","    for str_match in lst_match:\n","        ra, dec = re.split('\\+|-', str_match)\n","        ra_int = ra.split('.')[0]\n","        dec_int = dec.split('.')[0]\n","        if (4<=len(ra_int)<=6) and (3<=len(dec_int)<=6):\n","            lst_output.append(str_match)\n","    return lst_output\n","\n","#extract decimal coordinates\n","\n","def get_decimal_coordinates_sentences(sentence, start_index, lst_coords):\n","\n","    coord_regex = re.compile('\\D\\d{1,3}\\.\\d+'), re.compile('\\D[+-]?\\d{1,2}\\.\\d+')\n","\n","    ra_search_obj = coord_regex[0].search(sentence[start_index:])\n","\n","    if ra_search_obj:\n","        ra_end_ind = ra_search_obj.end()\n","        dec_search_obj = coord_regex[1].search(sentence[start_index+ra_end_ind:])\n","        if dec_search_obj:\n","            lst_coords.append((ra_search_obj.group(), dec_search_obj.group() ))\n","        start_index_next = start_index + ra_end_ind \n","        get_decimal_coordinates_sentences(sentence, start_index_next, lst_coords)\n","\n","def get_decimal_coordinates(content):\n","  lst = []\n","  for sentence in sent_tokenize(content):\n","    get_decimal_coordinates_sentences(sentence, 0, lst)\n","  return lst\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BF2Qew77jjRQ","colab_type":"code","colab":{}},"source":["# Load Model\n","\n","filename = '/content/drive/My Drive/StarWords/model.pickle'\n","model = pickle.load(open(filename, \"rb\"))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUwnk0bQcruv","colab_type":"code","colab":{}},"source":["# INFERENCE\n","\n","def classify(x_test_sentence):\n","    x_test_processed = process_sent(x_test_sentence)\n","    y_pred_test = model.predict([x_test_processed])\n","    \n","    return y_pred_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zq1sI_Z7xQqC","colab_type":"code","colab":{}},"source":["def extract_all_coordinates(input_string):\n","    \n","    all_matches = []\n","\n","    for sentence in my_tokenizer(input_string):\n","\n","        print_sentence(sentence)\n","        label = classify(sentence) #done\n","        \n","        object_name_formats = get_object_name_format(sentence)\n","        all_matches.extend(object_name_formats) #done\n","        # print(f'object name formats are {object_name_formats}')\n","\n","        matches = get_coordinates_except_decimal(sentence) # done\n","        # print(f'matches except decimal are {matches}')\n","        if label == 1:\n","            # print('label = ', label)\n","            if len(matches)==0:\n","                decimal_format = get_decimal_coordinates(sentence)\n","                # print(f'decimal format are {decimal_format}')\n","                matches.extend(decimal_format)  #to do\n","            all_matches.extend(matches)\n","        # print('-----------')\n","\n","\n","    return set(all_matches)"],"execution_count":0,"outputs":[]}]}